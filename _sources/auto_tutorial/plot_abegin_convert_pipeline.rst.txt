
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorial\plot_abegin_convert_pipeline.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorial_plot_abegin_convert_pipeline.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorial_plot_abegin_convert_pipeline.py:


.. _l-simple-deploy-1:

Train and deploy a scikit-learn pipeline
========================================

.. index:: pipeline, deployment

This program starts from an example in :epkg:`scikit-learn`
documentation: `Plot individual and voting regression predictions
<https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html>`_,
converts it into ONNX and finally computes the predictions
a different runtime.

.. contents::
    :local:


Training a pipeline
+++++++++++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 24-51

.. code-block:: default

    from pyquickhelper.helpgen.graphviz_helper import plot_graphviz
    import numpy
    from onnxruntime import InferenceSession
    from sklearn.datasets import load_diabetes
    from sklearn.ensemble import (
        GradientBoostingRegressor, RandomForestRegressor,
        VotingRegressor)
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import Pipeline
    from skl2onnx import to_onnx
    from mlprodict.onnxrt import OnnxInference


    X, y = load_diabetes(return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y)

    # Train classifiers
    reg1 = GradientBoostingRegressor(random_state=1, n_estimators=5)
    reg2 = RandomForestRegressor(random_state=1, n_estimators=5)
    reg3 = LinearRegression()

    ereg = Pipeline(steps=[
        ('voting', VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])),
    ])
    ereg.fit(X_train, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Pipeline(steps=[('voting',
                     VotingRegressor(estimators=[('gb',
                                                  GradientBoostingRegressor(n_estimators=5,
                                                                            random_state=1)),
                                                 ('rf',
                                                  RandomForestRegressor(n_estimators=5,
                                                                        random_state=1)),
                                                 ('lr', LinearRegression())]))])



.. GENERATED FROM PYTHON SOURCE LINES 52-60

Converts the model
++++++++++++++++++

The second argument gives a sample of the data
used to train the model. It is used to infer
the input type of the ONNX graph. It is converted
into single float and ONNX runtimes may not fully
support doubles.

.. GENERATED FROM PYTHON SOURCE LINES 60-64

.. code-block:: default


    onx = to_onnx(ereg, X_train[:1].astype(numpy.float32),
                  target_opset=12)








.. GENERATED FROM PYTHON SOURCE LINES 65-69

Prediction with ONNX
++++++++++++++++++++

The first example uses :epkg:`onnxruntime`.

.. GENERATED FROM PYTHON SOURCE LINES 69-77

.. code-block:: default


    sess = InferenceSession(onx.SerializeToString())
    pred_ort = sess.run(None, {'X': X_test.astype(numpy.float32)})[0]

    pred_skl = ereg.predict(X_test.astype(numpy.float32))

    pred_ort[:5], pred_skl[:5]





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    (array([[120.13089],
           [157.94276],
           [177.41113],
           [169.00098],
           [147.1565 ]], dtype=float32), array([120.13088318, 157.94275712, 177.41111238, 169.000977  ,
           147.15647114]))



.. GENERATED FROM PYTHON SOURCE LINES 78-85

.. _l-diff-dicrepencies:

Comparison
++++++++++

Before deploying, we need to compare that both
*scikit-learn* and *ONNX* return the same predictions.

.. GENERATED FROM PYTHON SOURCE LINES 85-96

.. code-block:: default



    def diff(p1, p2):
        p1 = p1.ravel()
        p2 = p2.ravel()
        d = numpy.abs(p2 - p1)
        return d.max(), (d / numpy.abs(p1)).max()


    print(diff(pred_skl, pred_ort))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (3.083668033809772e-05, 1.563262350903267e-07)




.. GENERATED FROM PYTHON SOURCE LINES 97-103

It looks good. Biggest errors (absolute and relative)
are within the margin error introduced by using
floats instead of doubles.
We can save the model into ONNX
format and compute the same predictions in many
platform using :epkg:`onnxruntime`.

.. GENERATED FROM PYTHON SOURCE LINES 105-113

Python runtime
++++++++++++++

A python runtime can be used as well to compute
the prediction. It is not meant to be used into
production (it still relies on python), but it is
useful to investigate why the conversion went wrong.
It uses module :epkg:`mlprodict`.

.. GENERATED FROM PYTHON SOURCE LINES 113-117

.. code-block:: default


    oinf = OnnxInference(onx, runtime="python_compiled")
    print(oinf)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    OnnxInference(...)
        def compiled_run(dict_inputs, yield_ops=None):
            if yield_ops is not None:
                raise NotImplementedError('yields_ops should be None.')
            # init: w0 (w0)
            # inputs
            X = dict_inputs['X']
            (var_2, ) = n0_linearregressor(X)
            (var_1, ) = n1_treeensembleregressor(X)
            (var_0, ) = n2_treeensembleregressor(X)
            (wvar_2, ) = n3_mul(var_2, w0)
            (wvar_1, ) = n4_mul(var_1, w0)
            (wvar_0, ) = n5_mul(var_0, w0)
            (fvar_2, ) = n6_flatten(wvar_2)
            (fvar_1, ) = n7_flatten(wvar_1)
            (fvar_0, ) = n8_flatten(wvar_0)
            (variable, ) = n9_sum(fvar_0, fvar_1, fvar_2)
            return {
                'variable': variable,
            }




.. GENERATED FROM PYTHON SOURCE LINES 118-119

It works almost the same way.

.. GENERATED FROM PYTHON SOURCE LINES 119-123

.. code-block:: default


    pred_pyrt = oinf.run({'X': X_test.astype(numpy.float32)})['variable']
    print(diff(pred_skl, pred_pyrt))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (3.083668033809772e-05, 1.563262350903267e-07)




.. GENERATED FROM PYTHON SOURCE LINES 124-126

Final graph
+++++++++++

.. GENERATED FROM PYTHON SOURCE LINES 126-130

.. code-block:: default


    ax = plot_graphviz(oinf.to_dot())
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)



.. image-sg:: /auto_tutorial/images/sphx_glr_plot_abegin_convert_pipeline_001.png
   :alt: plot abegin convert pipeline
   :srcset: /auto_tutorial/images/sphx_glr_plot_abegin_convert_pipeline_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.731 seconds)


.. _sphx_glr_download_auto_tutorial_plot_abegin_convert_pipeline.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/onnx/onnx.ai/sklearn-onnx//master?filepath=auto_examples/auto_tutorial/plot_abegin_convert_pipeline.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_abegin_convert_pipeline.py <plot_abegin_convert_pipeline.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_abegin_convert_pipeline.ipynb <plot_abegin_convert_pipeline.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
